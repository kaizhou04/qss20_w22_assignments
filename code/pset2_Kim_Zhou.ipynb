{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 (30 points)\n",
    "\n",
    "Use the same `sentencing_cleaned` data from Problem Set 1 for this assignment. You can either read in the pkl or csv but if csv, follow the instructions in the Github issue here to recast some columns as datetime: https://github.com/rebeccajohnson88/qss20_slides_activities/issues/6#issuecomment-1013546655\n",
    "\n",
    "In Problem Set 1, you investigated one form of disparity in the US criminal justice system: probation versus incarceration.\n",
    "\n",
    "Here, you'll investigate a second type of disparity---the length of a defendant's sentence---and also investigate the disparities faced by defendants sentenced by the same judge for the same crime. \n",
    "\n",
    "As a reminder, the codebook is available at this link:  https://datacatalog.cookcountyil.gov/api/views/tg8v-tm6u/files/8597cdda-f7e1-44d1-b0ce-0a4e43f8c980?download=true&filename=CCSAO%20Data%20Glossary.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "## repeated printouts\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read in the data and filter to defendants who were incarcerated and construct a sentence length variable (14 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read in the data\n",
    "- Filter to sentences that involve incarceration (same Illinois Department of Corrections logic as in problem set one: \n",
    "incarceration is indicated by `COMMITMENT_TYPE` == \"Illinois Department of Corrections\")\n",
    "- Using the `COMMITMENT_UNIT` column that represents sentence length, filter out the following non-numeric sentence lengths: Term, Pounds, Dollars, Ounces (year, months, natural life, days, hours, and weeks should remain)\n",
    "- Filter to Black or White defendants\n",
    "\n",
    "**Concepts tested and resources**: this question tests filtering rows based on logical conditions. Here are some resources:\n",
    "- DataCamp on .loc: https://campus.datacamp.com/courses/data-manipulation-with-pandas/slicing-and-indexing-dataframes?ex=3\n",
    "- Lecture 2 slide 19: https://campus.datacamp.com/courses/data-manipulation-with-pandas/slicing-and-indexing-dataframes?ex=3 \n",
    "- Row subsetting section in this activity: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hints on output**: we get 58289 rows remaining after this filtering. Don't worry about matching this exactly but try to get in the ballpark range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 135165 entries, 9 to 248145\n",
      "Data columns (total 52 columns):\n",
      " #   Column                             Non-Null Count   Dtype         \n",
      "---  ------                             --------------   -----         \n",
      " 0   CASE_ID                            135165 non-null  int64         \n",
      " 1   CASE_PARTICIPANT_ID                135165 non-null  int64         \n",
      " 2   RECEIVED_DATE                      135165 non-null  object        \n",
      " 3   OFFENSE_CATEGORY                   135165 non-null  object        \n",
      " 4   PRIMARY_CHARGE_FLAG                135165 non-null  bool          \n",
      " 5   CHARGE_ID                          135165 non-null  int64         \n",
      " 6   CHARGE_VERSION_ID                  135165 non-null  int64         \n",
      " 7   DISPOSITION_CHARGED_OFFENSE_TITLE  135165 non-null  object        \n",
      " 8   CHARGE_COUNT                       135165 non-null  int64         \n",
      " 9   DISPOSITION_DATE                   135165 non-null  object        \n",
      " 10  DISPOSITION_CHARGED_CHAPTER        135165 non-null  object        \n",
      " 11  DISPOSITION_CHARGED_ACT            134268 non-null  object        \n",
      " 12  DISPOSITION_CHARGED_SECTION        134268 non-null  object        \n",
      " 13  DISPOSITION_CHARGED_CLASS          135160 non-null  object        \n",
      " 14  DISPOSITION_CHARGED_AOIC           135160 non-null  object        \n",
      " 15  CHARGE_DISPOSITION                 135165 non-null  object        \n",
      " 16  CHARGE_DISPOSITION_REASON          478 non-null     object        \n",
      " 17  SENTENCE_JUDGE                     135165 non-null  object        \n",
      " 18  SENTENCE_COURT_NAME                134955 non-null  object        \n",
      " 19  SENTENCE_COURT_FACILITY            134647 non-null  object        \n",
      " 20  SENTENCE_PHASE                     135165 non-null  object        \n",
      " 21  SENTENCE_DATE                      135165 non-null  object        \n",
      " 22  SENTENCE_TYPE                      135165 non-null  object        \n",
      " 23  CURRENT_SENTENCE_FLAG              135165 non-null  bool          \n",
      " 24  COMMITMENT_TYPE                    134172 non-null  object        \n",
      " 25  COMMITMENT_TERM                    134172 non-null  object        \n",
      " 26  COMMITMENT_UNIT                    134172 non-null  object        \n",
      " 27  LENGTH_OF_CASE_in_Days             127360 non-null  float64       \n",
      " 28  AGE_AT_INCIDENT                    129743 non-null  float64       \n",
      " 29  RACE                               134407 non-null  object        \n",
      " 30  GENDER                             134705 non-null  object        \n",
      " 31  INCIDENT_CITY                      128330 non-null  object        \n",
      " 32  INCIDENT_BEGIN_DATE                129923 non-null  object        \n",
      " 33  INCIDENT_END_DATE                  11541 non-null   object        \n",
      " 34  LAW_ENFORCEMENT_AGENCY             130079 non-null  object        \n",
      " 35  LAW_ENFORCEMENT_UNIT               41976 non-null   object        \n",
      " 36  ARREST_DATE                        132438 non-null  object        \n",
      " 37  FELONY_REVIEW_DATE                 92677 non-null   object        \n",
      " 38  FELONY_REVIEW_RESULT               92677 non-null   object        \n",
      " 39  ARRAIGNMENT_DATE                   127360 non-null  object        \n",
      " 40  UPDATED_OFFENSE_CATEGORY           135165 non-null  object        \n",
      " 41  is_changed_offense                 135165 non-null  bool          \n",
      " 42  simplified_offense_derived         135165 non-null  object        \n",
      " 43  is_black_derived                   135165 non-null  bool          \n",
      " 44  is_hisp_derived                    135165 non-null  bool          \n",
      " 45  is_white_derived                   135165 non-null  bool          \n",
      " 46  is_other_derived                   135165 non-null  bool          \n",
      " 47  is_male_derived                    135165 non-null  bool          \n",
      " 48  age_derived                        129743 non-null  float64       \n",
      " 49  sentenceymd_derived                135165 non-null  datetime64[ns]\n",
      " 50  sentenceym_derived                 135165 non-null  datetime64[ns]\n",
      " 51  judgeid_derived                    135165 non-null  object        \n",
      "dtypes: bool(8), datetime64[ns](2), float64(3), int64(5), object(34)\n",
      "memory usage: 47.4+ MB\n"
     ]
    }
   ],
   "source": [
    "sentencing_cleaned = pd.read_pickle(\"sentencing_cleaned.pkl\")\n",
    "\n",
    "sentencing_cleaned.info()\n",
    "\n",
    "sentencing_cleaned = sentencing_cleaned[sentencing_cleaned.COMMITMENT_TYPE == \"Illinois Department of Corrections\"]\n",
    "\n",
    "sentencing_cleaned = sentencing_cleaned[(sentencing_cleaned.COMMITMENT_UNIT != 'Term') & (sentencing_cleaned.COMMITMENT_UNIT != 'Pounds') & (sentencing_cleaned.COMMITMENT_UNIT != 'Dollars') & (sentencing_cleaned.COMMITMENT_UNIT != 'Ounces')]\n",
    "\n",
    "sentencing_cleaned['is_black_or_white'] = (sentencing_cleaned.is_black_derived == True) | (sentencing_cleaned.is_white_derived == True)\n",
    "\n",
    "sentencing_cleaned = sentencing_cleaned[sentencing_cleaned.is_black_or_white]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, follow the instructions in the codebook (combining `COMMITMENT_TERM` with `COMMITMENT_UNIT`) to create a standard sentence length in days column (`senlength_derived`) that measures the sentence in **days**. To simplify, you can assume that:\n",
    "\n",
    "- 1 hour = 1/24th of a day\n",
    "- 1 year = 365 days\n",
    "- 1 month = 30.5 days\n",
    "- 1 week = 7 days\n",
    "- Natural life = difference between the age of 100 and the defendant's age at incident (cleaned; if missing, code to age 20); note that this is a simplification since age at incident != age at sentencing \n",
    "\n",
    "Print the following cols for an example of each type (eg an example of originally hours; an example of natural life): `COMMITMENT_TERM`, `COMMITMENT_UNIT`, `age_derived` and your new standardized sentence length column (`senlength_derived`)\n",
    "\n",
    "Print the summary of that column (`senlength_derived`) using the .describe() command\n",
    "\n",
    "**Concepts tested and resources**: there are many approaches but a couple ways are:\n",
    "- np.select covered in the slides and this activity notebook: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb \n",
    "- writing a function that takes in one row as an argument and has a series of if, elif, else conditions where different commitment_units are translated into days. To execute this function, you can use the .apply function but apply it with axis = 1 (row-wise). Resources for that include: (1) the activity notebook on user-defined functions (https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/02_loopsfunctions_solutions.ipynb); (2) the activity notebook covering apply: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hint on output**: see GitHub issue for the summary stats we get from running .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_derived</th>\n",
       "      <th>COMMITMENT_UNIT</th>\n",
       "      <th>COMMITMENT_TERM</th>\n",
       "      <th>senlength_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Natural Life</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58284</th>\n",
       "      <td>45.0</td>\n",
       "      <td>Months</td>\n",
       "      <td>18.0</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58285</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58286</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58287</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58288</th>\n",
       "      <td>35.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58289 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_derived COMMITMENT_UNIT COMMITMENT_TERM senlength_derived\n",
       "0             27.0         Year(s)            62.0           22630.0\n",
       "1             30.0    Natural Life             1.0           25550.0\n",
       "2              NaN         Year(s)            10.0            3650.0\n",
       "3             17.0         Year(s)            20.0            7300.0\n",
       "4             23.0         Year(s)            45.0           16425.0\n",
       "...            ...             ...             ...               ...\n",
       "58284         45.0          Months            18.0             549.0\n",
       "58285         44.0         Year(s)             5.0            1825.0\n",
       "58286         33.0         Year(s)             2.0             730.0\n",
       "58287         24.0         Year(s)             2.0             730.0\n",
       "58288         35.0         Year(s)             1.0             365.0\n",
       "\n",
       "[58289 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code here on translation of units\n",
    "# sentencing_cleaned['COMMITMENT_TERM']\n",
    "sentencing_cleaned['senlength_derived'] = np.select([sentencing_cleaned['COMMITMENT_UNIT']=='Year(s)', \n",
    "                                                     sentencing_cleaned['COMMITMENT_UNIT']=='Months', \n",
    "                                                     sentencing_cleaned['COMMITMENT_UNIT']=='Weeks', \n",
    "                                                     sentencing_cleaned['COMMITMENT_UNIT']=='Hours', \n",
    "                                                     sentencing_cleaned['COMMITMENT_UNIT']=='Natural Life'],\n",
    "                                                    [sentencing_cleaned['COMMITMENT_TERM'].astype(float) * 365,\n",
    "                                                    sentencing_cleaned['COMMITMENT_TERM'].astype(float) * 30.5,\n",
    "                                                    sentencing_cleaned['COMMITMENT_TERM'].astype(float) * 7,\n",
    "                                                    sentencing_cleaned['COMMITMENT_TERM'].astype(float) / 24,\n",
    "                                                    (100 - sentencing_cleaned['AGE_AT_INCIDENT'].astype(float)) * 365],\n",
    "                                                    default=sentencing_cleaned['COMMITMENT_TERM'])\n",
    "\n",
    "sentencing_cleaned = sentencing_cleaned.reset_index()\n",
    "sentencing_cleaned[['age_derived', 'COMMITMENT_UNIT', 'COMMITMENT_TERM', 'senlength_derived']]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_derived</th>\n",
       "      <th>COMMITMENT_UNIT</th>\n",
       "      <th>COMMITMENT_TERM</th>\n",
       "      <th>senlength_derived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Natural Life</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Year(s)</td>\n",
       "      <td>62.0</td>\n",
       "      <td>22630.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Months</td>\n",
       "      <td>18.0</td>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Weeks</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>40.0</td>\n",
       "      <td>Days</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42044</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Hours</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_derived COMMITMENT_UNIT COMMITMENT_TERM senlength_derived\n",
       "1             30.0    Natural Life             1.0           25550.0\n",
       "0             27.0         Year(s)            62.0           22630.0\n",
       "58            29.0          Months            18.0             549.0\n",
       "7656          23.0           Weeks             2.0              14.0\n",
       "2541          40.0            Days            90.0              90.0\n",
       "42044         22.0           Hours             1.0          0.041667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code here on printing example of each type of committment unit and what it's senlength_derived is\n",
    "sentencing_cleaned[['age_derived', 'COMMITMENT_UNIT', 'COMMITMENT_TERM', 'senlength_derived']].iloc[[1, 0, 58, 7656, 2541, 42044]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     58289.0\n",
       "unique      240.0\n",
       "top         365.0\n",
       "freq      14456.0\n",
       "Name: senlength_derived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code here with the .describe() command summary of the senlength_derived column\n",
    "sentencing_cleaned['senlength_derived'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Examine disparities in length within the same judge and offense category: constructing matched pairs (16 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the above ~58k row dataset that is subsetted to only to sentences involving incarceration. Then, further subset the rows to:\n",
    "- Rows where `judgeid_derived` = `judge_21` \n",
    "- `simplified_offense_derived` == \"Narcotics\"\n",
    "\n",
    "Use `shape` to print the dimensions of the resulting dataframe\n",
    "\n",
    "**Concepts and resources**: row subsetting using logical conditions; see above resources\n",
    "\n",
    "**Hint on output**: we get 53 rows after this filtering step. Don't worry about matching this exactly but try to get in the ballpark range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 55)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here to filter rows and check the shape\n",
    "sentencing_cleaned = sentencing_cleaned[(sentencing_cleaned['judgeid_derived']=='judge_21') & (sentencing_cleaned['simplified_offense_derived']=='Narcotics')]\n",
    "sentencing_cleaned.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "For each defendant sentenced by judge_21, you want to construct a \"matched group\" of defendants who:\n",
    "\n",
    "- Are the same exact age as the focal defendant (`age_derived`) and\n",
    "- Are the same gender as the focal defendant (`is_male_derived`) but \n",
    "- Differ in race from the focal defendant (`is_black_derived`/`is_white_derived`)\n",
    "\n",
    "Write a user-defined function to find any/all matched defendants for each focal defendant of judge 21. You can structure the function in various ways but one way is to write a function similar to the class example where we iterate over different DC crimes (focal crimes) and find similar crimes. For this problem, we want to:\n",
    "\n",
    "- Iterate over unique defendants sentenced by judge 21 (use `CASE_PARTICIPANT_ID` to identify each unique defendant)\n",
    "- Find other defendants in the judge 21 pool who (1) have a different race from that focal defendant but (2) the same gender and age \n",
    "\n",
    "\n",
    "**Concepts and resources**: \n",
    "\n",
    "- Slides and activity code on user-defined functions and iterating using list comprehension: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/02_loopsfunctions_solutions.ipynb\n",
    "- You can either write code in the function to add columns with the attributes of the focal defendant (existing material) or using `pd.merge` to join these on after; we'll be covering `pd.merge` Monday 01.24 but here are last year's slides (slide 17-20) in meantime: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/slides/s21_slides/qss20_s21_class4.pdf \n",
    "\n",
    "\n",
    "**Hints on output**: \n",
    "\n",
    "- Some focal defendants may not have any matches; they can be excluded from the results \n",
    "- In the way we wrote our function, each iteration of the function returns a single dataframe; because we execute via list comprehension, the output of this step is a list of dataframes (it's okay if you take a diff approach!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here to define function\n",
    "def defendant_match(focal_defendant: pd.DataFrame):\n",
    "    result = sentencing_cleaned[(sentencing_cleaned['age_derived']==focal_defendant['age_derived']) &\n",
    "                               (sentencing_cleaned['is_male_derived']==focal_defendant['is_male_derived']) &\n",
    "                               (sentencing_cleaned['is_black_derived']!=focal_defendant['is_black_derived'])]\n",
    "    result['focal'] = focal_defendant['CASE_PARTICIPANT_ID']\n",
    "    return result\n",
    "\n",
    "# focus = sentencing_cleaned.iloc[4]\n",
    "# focus[['CASE_PARTICIPANT_ID', 'age_derived', 'is_male_derived', 'is_black_derived']]\n",
    "# defendant_match(focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaizh\\AppData\\Local\\Temp/ipykernel_2012/1896517501.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## your code here to execute the function for all defendants sentenced by judge_21 \n",
    "all_matches = []\n",
    "for index in range(0, sentencing_cleaned.shape[0]):\n",
    "    defendant = sentencing_cleaned.iloc[index]\n",
    "    all_matches.append(defendant_match(defendant))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from Part B, use `pd.concat` or another approach to create a dataframe that compares the (1) race and sentence length for the focal defendant to (2) the sentence length for other defendants. Using this dataframe, show this comparison for focal defendant: `CASE_PARTICIPANT_ID` == `808109112733`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_PARTICIPANT_ID_focal</th>\n",
       "      <th>CASE_PARTICIPANT_ID_match</th>\n",
       "      <th>is_black_derived_focal</th>\n",
       "      <th>senlength_derived_focal</th>\n",
       "      <th>senlength_derived_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>808109112733</td>\n",
       "      <td>768307912970</td>\n",
       "      <td>True</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>808109112733</td>\n",
       "      <td>769939231128</td>\n",
       "      <td>True</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>808109112733</td>\n",
       "      <td>774967571640</td>\n",
       "      <td>True</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CASE_PARTICIPANT_ID_focal  CASE_PARTICIPANT_ID_match  \\\n",
       "56               808109112733               768307912970   \n",
       "57               808109112733               769939231128   \n",
       "58               808109112733               774967571640   \n",
       "\n",
       "    is_black_derived_focal senlength_derived_focal senlength_derived_match  \n",
       "56                    True                  2190.0                   730.0  \n",
       "57                    True                  2190.0                   730.0  \n",
       "58                    True                  2190.0                   365.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code to rowbind all matches and to highlight the comparison\n",
    "match_df = pd.concat(all_matches)\n",
    "merged = match_df.merge(sentencing_cleaned, left_on='focal', right_on='CASE_PARTICIPANT_ID', suffixes=('_match', '_focal'))\n",
    "merged = merged[['CASE_PARTICIPANT_ID_focal', 'CASE_PARTICIPANT_ID_match', 'is_black_derived_focal', 'senlength_derived_focal', 'senlength_derived_match']]\n",
    "## for the example defendant \n",
    "example = merged.loc[merged['CASE_PARTICIPANT_ID_focal']==808109112733]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from Part C, group by the focal defendant's race and find the proportion of that defendant's matches who had a LONGER sentence than the focal defendant\n",
    "\n",
    "**Concepts and resources**: can use groupby and agg\n",
    "\n",
    "- Groupby and agg code: https://github.com/rebeccajohnson88/qss20_slides_activities/blob/main/activities/w22_activities/solutions/00_pandas_datacleaning_solutions.ipynb\n",
    "\n",
    "**Hints on output**: since we're grouping by race in the full pool, the resulting output should have two values: one for the rate at which Black defendants have matches with higher sentences; another for the rate at which White defendants have matches with higher sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_black_derived_focal\n",
       "False    0.451613\n",
       "True     0.483871\n",
       "Name: match_longer, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here \n",
    "merged['match_longer'] = merged['senlength_derived_match'] > merged['senlength_derived_focal']\n",
    "merged.groupby('is_black_derived_focal')['match_longer'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 1-2 lines commenting on the results from Part D. What other defendant or offense-level characteristics would you like to match on to investigate claims about racial disparities? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data, there is a higher proportion of white matches that have a longer sentence when compared to their black focal defendant than of black matches that have a longer sentence when compared to their white focal defendant. \n",
    "It might be interesting to look at the sentencing disparaties between white and black defendants by matching on different crimes such as violent crimes. It might also be interesting to match based on the date of incident to see how sentencing disparaties have changed over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optional extra credit/challenge exercise (2 points): examine disparities across multiple judges\n",
    "\n",
    "In problem 1.2, we focused on one judge: judge 21.\n",
    "    \n",
    "For this extra credit exercise, use the same data filtered to (1) incarceration, (2) Black/White only, and (3) narcotics offenses. \n",
    "    \n",
    "- Get judges with a high enough sample of each group to compare sentencing: filter to each judge with at least 20 Black and at least 20 white defendants\n",
    "- For each of the judges, calculate the median sentence length for their Black defendants and (2) the median sentence length for their white defendants \n",
    "- Create a barplot with the result: factor variable on x axis for each judge_id who qualifies; separate bars/colors by race\n",
    "- Write a 1-2 sentence interpretation - if we assume that cases/defendants are randomly assigned to sentencing judges, what might this suggest about the role of judicial discretion in these disparities?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optional extra credit/challenge exercise (2 points): impute possible demographic correlate of sentencing\n",
    "\n",
    "The previous exercises showed large differences in sentences between judges/differences in disparities. You become interested in how the judge's own demographic attributes are correlated with sentencing. Going back to the judge's name (`SENTENCE JUDGE`), parse their first name and try to probabilistically infer his or her gender. Then, investigate whether disparities differ between \"likely female\" and \"likely male\" judges. \n",
    "\n",
    "**Note on ethics of probabilistic inference of attributes based on name**: Using names to infer demographic characteristics has become increasingly popular with the rise of \"digital trace data\" that often lacks explicit demographic fields (e.g., tweets just have usernames and profiles; academic citation networks just have author names). But there are many valid ethical critiques of this practice. In the case of gender, a person's assigned name at birth clearly does not always map onto their self-identified gender, both due to genders beyond the binary of male/female and names like \"Morgan.\" A couple critiques I link to are:\n",
    "\n",
    "- [This blog post](https://scatter.wordpress.com/2021/07/30/who-writes-social-science/)\n",
    "- [Urban Institute ethical risks of race/ethnicity imputation - applies to gender](https://www.urban.org/research/publication/five-ethical-risks-consider-filling-missing-race-and-ethnicity-data)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
